{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2348dfe-0fe4-4e4a-b073-883b2112f0eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebda859-73f7-4b2a-90d4-0771ba4feda5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os, pathlib, shutil, platform\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d6f77-7c4b-4fe6-8ffe-1be0443fe26c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe19ef5e-d678-4ce6-aa83-6336bbe6d89c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freight_aggregation(crt_year, metric_column, analysis_type, regional_flag='regional', non_jets_flag='nonjets'):\n",
    "    \"\"\"\n",
    "    For each year in the years_list passed to the function, the sum of freight for each month's flights that year is computed and saved in a csv file.\n",
    "    Thus 12 monthly values are calculated for each analysis type.\n",
    "    \n",
    "    Note that this is made for non-jets only, as indicated by using only 'AIRCRAFT_GROUP' codes <= 5. Jets have codes >= 6. \n",
    "    Additionally, this is made for regional flights, which are those with nautical mile distances b/w 75-500.\n",
    "    \n",
    "    Analysis 0: origin US, dest US\n",
    "    Analysis 1: origin US, dest non-US\n",
    "    Analysis 2: origin non-US, dest US\n",
    "    Analysis 3: origin all, dest all\n",
    "    Analysis 4: origin all states, dest all\n",
    "    Analysis 5: origin all, dest all states\n",
    "    Analysis 6: origin US, dest all\n",
    "    Analysis 7: origin AFW, destination all \n",
    "    Analysis 8: origin all, destination AFW\n",
    "    Analysis 9: origin KIS, destination all\n",
    "    Analysis 10: origin all, destination KIS\n",
    "AFW (Perot Field Fort Worth Alliance Airport) is an airport located in Fort Worth, Texas. \n",
    "KIS (Visalia Municipal Airport) is an airport located in Visalia, California.\n",
    "Both are airports of interest to the PAAV team.\n",
    "    \n",
    "    # cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 10194)]\n",
    "# cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 10194)]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_data = pd.read_csv(str('./../../../data/paav_cargo/T-100Segment_AllCarriers/DL_SelectFields_AllMonths_AllGeo_'+\n",
    "                 str(crt_year)\n",
    "                 +'/T_T100_SEGMENT_ALL_CARRIER.csv'))\n",
    "\n",
    "    cleaned_data.drop(cleaned_data[cleaned_data['DISTANCE'] == 0].index, inplace = True)\n",
    "    cleaned_data.dropna(subset=['ORIGIN_STATE_NM'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['DEST_STATE_NM'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['ORIGIN_COUNTRY'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['DEST_COUNTRY'], inplace = True)\n",
    "    cleaned_data.drop(cleaned_data[cleaned_data['DEPARTURES_PERFORMED'] == 0].index, inplace = True)\n",
    "    cleaned_data['DISTANCE'] = cleaned_data['DISTANCE'].apply(lambda x: x*0.868976) #convert miles to nautical miles\n",
    "\n",
    "    cleaned_data['ds'] = cleaned_data['YEAR'].map(str) +\"-\"+ cleaned_data[\"MONTH\"].map(str) + \"-01\"\n",
    "    cleaned_data['ds'] = pd.to_datetime(cleaned_data['ds'],format='%Y-%m-%d')\n",
    "    # cleaned_data.sort_values(by='ds', ascending=True, inplace = True)\n",
    "\n",
    "    if regional_flag=='regional':\n",
    "        #specific to regionality as mentioned in function desc\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DISTANCE'] <= 500) & (cleaned_data['DISTANCE'] >= 75)].reset_index()\n",
    "        cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "    if non_jets_flag=='nonjets':\n",
    "        #specific to nonjets as mentioned in function desc\n",
    "        cleaned_data = (cleaned_data[cleaned_data['AIRCRAFT_GROUP'] <= 5]).reset_index()\n",
    "        cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "\n",
    "    if analysis_type == 0:\n",
    "        print(crt_year)\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US') & (cleaned_data['DEST_COUNTRY'] =='US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 1:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US') & (cleaned_data['DEST_COUNTRY'] != 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'non-US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 2:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] != 'US') & (cleaned_data['DEST_COUNTRY'] == 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'non-US'\n",
    "        cleaned_data['dest'] = 'US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 3:\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "\n",
    "\n",
    "#     elif analysis_type == 4:\n",
    "#         allstates = [None] * cleaned_data['ORIGIN_STATE_NM'].nunique()\n",
    "#         allstates_index = 0\n",
    "#         for crt_state in cleaned_data['ORIGIN_STATE_NM'].unique():\n",
    "#             crtdata = cleaned_data[(cleaned_data['ORIGIN_STATE_NM'] == crt_state)].groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "#             crtdata.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "#             crtdata['origin'] = crt_state\n",
    "#             crtdata['dest'] = 'all'\n",
    "#             allstates[allstates_index] = crtdata\n",
    "#             allstates_index=allstates_index+1\n",
    "\n",
    "#         crtdata = pd.concat(allstates)\n",
    "#         cleaned_data = crtdata.reset_index()\n",
    "#         # cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "    elif analysis_type == 4:\n",
    "        cleaned_data= cleaned_data.groupby(['ds', 'ORIGIN_STATE_NM'])['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights', 'ORIGIN_STATE_NM': 'origin'}, inplace = True)\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "    elif analysis_type == 5:\n",
    "        cleaned_data= cleaned_data.groupby(['ds', 'DEST_STATE_NM'])['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights', 'DEST_STATE_NM': 'dest'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        \n",
    "    elif analysis_type == 6:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 7:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 10194)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'AFW'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 8:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 10194)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'AFW'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 9:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 15601)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'KIS'\n",
    "        cleaned_data['dest'] = 'all' \n",
    "        \n",
    "    elif analysis_type == 10:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 15601)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'KIS' \n",
    "      \n",
    "\n",
    "    cleaned_data.to_csv('./../../../data/paav_cargo/agg_data/freight_aggregation__' +\n",
    "                            str(crt_year) + '_analysis'+ str(analysis_type) + '_' + regional_flag+ '_' + non_jets_flag +\n",
    "                        '.csv', mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35551945-80c7-4161-8399-d822cceafa31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years_list = [yr for yr in range (1990,2024)]\n",
    "\n",
    "for analysis_type in range(0,11):\n",
    "    for regional_flag in [ 'alldistance' , 'regional']:\n",
    "        for non_jets_flag in ['jetsandnonjets', 'nonjets']: #need to add jets\n",
    "            for crt_year in years_list:\n",
    "                data_file = './../../../data/paav_cargo/agg_data/freight_aggregation__' + \\\n",
    "                                    str(crt_year) + '_analysis'+ str(analysis_type)+ '_' + regional_flag+ '_' + non_jets_flag +'.csv'\n",
    "                if os.path.exists(data_file): os.remove(data_file), print(\"Deleted file \" +data_file + \".\")\n",
    "                else: print(\"The file \" +data_file + \" does not exist\")\n",
    "\n",
    "                freight_aggregation(crt_year, 'FREIGHT', analysis_type, regional_flag, non_jets_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd5448d-86eb-4d84-85da-165e60d52320",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e67b9d-cb47-4ebb-b96d-3da7101abdef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def spike_investigation_2014_analysis9(crt_year):\n",
    "#     cleaned_data = pd.read_csv(str('./../../../data/paav_cargo/T-100Segment_AllCarriers/DL_SelectFields_AllMonths_AllGeo_'+\n",
    "#                  str(crt_year)\n",
    "#                  +'/T_T100_SEGMENT_ALL_CARRIER.csv'))\n",
    "\n",
    "#     cleaned_data.drop(cleaned_data[cleaned_data['DISTANCE'] == 0].index, inplace = True)\n",
    "#     cleaned_data.dropna(subset=['ORIGIN_STATE_NM'], inplace = True)\n",
    "#     cleaned_data.dropna(subset=['DEST_STATE_NM'], inplace = True)\n",
    "#     cleaned_data.dropna(subset=['ORIGIN_COUNTRY'], inplace = True)\n",
    "#     cleaned_data.dropna(subset=['DEST_COUNTRY'], inplace = True)\n",
    "#     cleaned_data.drop(cleaned_data[cleaned_data['DEPARTURES_PERFORMED'] == 0].index, inplace = True)\n",
    "#     cleaned_data['DISTANCE'] = cleaned_data['DISTANCE'].apply(lambda x: x*0.868976) #convert miles to nautical miles\n",
    "\n",
    "#     cleaned_data['ds'] = cleaned_data['YEAR'].map(str) +\"-\"+ cleaned_data[\"MONTH\"].map(str) + \"-01\"\n",
    "#     cleaned_data['ds'] = pd.to_datetime(cleaned_data['ds'],format='%Y-%m-%d')\n",
    "#     # cleaned_data.sort_values(by='ds', ascending=True, inplace = True)\n",
    "\n",
    "#     if regional_flag=='regional':\n",
    "#         #specific to regionality as mentioned in function desc\n",
    "#         cleaned_data = cleaned_data[(cleaned_data['DISTANCE'] <= 500) & (cleaned_data['DISTANCE'] >= 75)].reset_index()\n",
    "#         cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "#     if non_jets_flag=='nonjets':\n",
    "#         #specific to nonjets as mentioned in function desc\n",
    "#         cleaned_data = (cleaned_data[cleaned_data['AIRCRAFT_GROUP'] <= 5]).reset_index()\n",
    "#         cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "        \n",
    "#     cleaned_data = cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 15601)]\n",
    "#     # cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "#     # cleaned_data.reset_index(inplace=True)\n",
    "#     # cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "#     cleaned_data=cleaned_data[['AIRLINE_ID', 'YEAR', 'FREIGHT', 'ds']]\n",
    "#     cleaned_data['origin'] = 'KIS'\n",
    "#     cleaned_data['dest'] = 'all'\n",
    "    \n",
    "#     cleaned_data.to_csv('./../../../data/paav_cargo/2014_boom_analysis9_investigation/2014_boom_analysis9_investigation' +\n",
    "#                             str(crt_year) + '_analysis'+ str(9) + '_' + regional_flag+ '_' + non_jets_flag +\n",
    "#                         '.csv', mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b7c2e0-90a6-4640-bf38-c03b3aa33073",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for crt_year in [yr for yr in range(2002,2024)]:\n",
    "#     spike_investigation_2014_analysis9(crt_year)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28949ea6-042d-43a0-9bdf-1a78722221a3",
   "metadata": {},
   "source": [
    "This is the improved function, which now calculates monthly sums not only for nonjets and jetsandnonjets, but now just uniquely jets too!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6882c4-a590-4774-8c38-a357e5510660",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def freight_aggregation(crt_year, metric_column, analysis_type, regional_flag, aircraft_flag):\n",
    "    \"\"\"\n",
    "    For each year in the years_list passed to the function, the sum of freight for each month's flights that year is computed and saved in a csv file.\n",
    "    Thus 12 monthly values are calculated for each analysis type.\n",
    "    \n",
    "    This is made for non-jets, jets, and both. We use 'AIRCRAFT_GROUP' codes to distinguish between them: <= 5 are nonjets, jets have codes >= 6. \n",
    "    Additionally, this is made for regional flights, which are those with nautical mile distances b/w 75-500.\n",
    "    \n",
    "    Analysis 0: origin US, dest US\n",
    "    Analysis 1: origin US, dest non-US\n",
    "    Analysis 2: origin non-US, dest US\n",
    "    Analysis 3: origin all, dest all\n",
    "    Analysis 4: origin all states, dest all\n",
    "    Analysis 5: origin all, dest all states\n",
    "    Analysis 6: origin US, dest all\n",
    "    Analysis 7: origin AFW, destination all \n",
    "    Analysis 8: origin all, destination AFW\n",
    "    Analysis 9: origin KIS, destination all\n",
    "    Analysis 10: origin all, destination KIS\n",
    "AFW (Perot Field Fort Worth Alliance Airport) is an airport located in Fort Worth, Texas. \n",
    "KIS (Visalia Municipal Airport) is an airport located in Visalia, California.\n",
    "Both are airports of interest to the PAAV team.\n",
    "\n",
    "aircraft_flag_options = ['nonjets', 'jets', 'jetsandnonjets']\n",
    "    \n",
    "# cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 10194)]\n",
    "# cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 10194)]\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    cleaned_data = pd.read_csv(str('./../../../data/paav_cargo/T-100Segment_AllCarriers/DL_SelectFields_AllMonths_AllGeo_'+\n",
    "                 str(crt_year)\n",
    "                 +'/T_T100_SEGMENT_ALL_CARRIER.csv'))\n",
    "\n",
    "    cleaned_data.drop(cleaned_data[cleaned_data['DISTANCE'] == 0].index, inplace = True)\n",
    "    cleaned_data.dropna(subset=['ORIGIN_STATE_NM'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['DEST_STATE_NM'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['ORIGIN_COUNTRY'], inplace = True)\n",
    "    cleaned_data.dropna(subset=['DEST_COUNTRY'], inplace = True)\n",
    "    cleaned_data.drop(cleaned_data[cleaned_data['DEPARTURES_PERFORMED'] == 0].index, inplace = True)\n",
    "    cleaned_data['DISTANCE'] = cleaned_data['DISTANCE'].apply(lambda x: x*0.868976) #convert miles to nautical miles\n",
    "\n",
    "    cleaned_data['ds'] = cleaned_data['YEAR'].map(str) +\"-\"+ cleaned_data[\"MONTH\"].map(str) + \"-01\"\n",
    "    cleaned_data['ds'] = pd.to_datetime(cleaned_data['ds'],format='%Y-%m-%d')\n",
    "    # cleaned_data.sort_values(by='ds', ascending=True, inplace = True)\n",
    "\n",
    "    if regional_flag=='regional':\n",
    "        #specific to regionality as mentioned in function desc\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DISTANCE'] <= 500) & (cleaned_data['DISTANCE'] >= 75)].reset_index()\n",
    "        cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "    if aircraft_flag=='nonjets':\n",
    "        #specific to nonjets as mentioned in function desc\n",
    "        cleaned_data = (cleaned_data[cleaned_data['AIRCRAFT_GROUP'] <= 5]).reset_index()\n",
    "        cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "        \n",
    "    if aircraft_flag=='jets':\n",
    "        #specific to nonjets as mentioned in function desc\n",
    "        cleaned_data = (cleaned_data[cleaned_data['AIRCRAFT_GROUP'] >= 6]).reset_index()\n",
    "        cleaned_data.drop(['index'], axis=1, inplace = True)    \n",
    "\n",
    "\n",
    "    if analysis_type == 0:\n",
    "        print(crt_year)\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US') & (cleaned_data['DEST_COUNTRY'] =='US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 1:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US') & (cleaned_data['DEST_COUNTRY'] != 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'non-US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 2:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] != 'US') & (cleaned_data['DEST_COUNTRY'] == 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'non-US'\n",
    "        cleaned_data['dest'] = 'US'\n",
    "\n",
    "\n",
    "    elif analysis_type == 3:\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "\n",
    "\n",
    "#     elif analysis_type == 4:\n",
    "#         allstates = [None] * cleaned_data['ORIGIN_STATE_NM'].nunique()\n",
    "#         allstates_index = 0\n",
    "#         for crt_state in cleaned_data['ORIGIN_STATE_NM'].unique():\n",
    "#             crtdata = cleaned_data[(cleaned_data['ORIGIN_STATE_NM'] == crt_state)].groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "#             crtdata.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "#             crtdata['origin'] = crt_state\n",
    "#             crtdata['dest'] = 'all'\n",
    "#             allstates[allstates_index] = crtdata\n",
    "#             allstates_index=allstates_index+1\n",
    "\n",
    "#         crtdata = pd.concat(allstates)\n",
    "#         cleaned_data = crtdata.reset_index()\n",
    "#         # cleaned_data.drop(['index'], axis=1, inplace = True)\n",
    "\n",
    "    elif analysis_type == 4:\n",
    "        cleaned_data= cleaned_data.groupby(['ds', 'ORIGIN_STATE_NM'])['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights', 'ORIGIN_STATE_NM': 'origin'}, inplace = True)\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "    elif analysis_type == 5:\n",
    "        cleaned_data= cleaned_data.groupby(['ds', 'DEST_STATE_NM'])['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights', 'DEST_STATE_NM': 'dest'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        \n",
    "    elif analysis_type == 6:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_COUNTRY'] == 'US')]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'US'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 7:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 10194)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'AFW'\n",
    "        cleaned_data['dest'] = 'all'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 8:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 10194)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'AFW'\n",
    "        \n",
    "        \n",
    "    elif analysis_type == 9:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['ORIGIN_AIRPORT_ID'] == 15601)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'KIS'\n",
    "        cleaned_data['dest'] = 'all' \n",
    "        \n",
    "    elif analysis_type == 10:\n",
    "        cleaned_data = cleaned_data[(cleaned_data['DEST_AIRPORT_ID'] == 15601)]\n",
    "        cleaned_data= cleaned_data.groupby('ds')['FREIGHT'].agg(['sum','count'])\n",
    "        cleaned_data.reset_index(inplace=True)\n",
    "        cleaned_data.rename(columns={'sum': 'y', 'count': 'num flights'}, inplace = True)\n",
    "        cleaned_data['origin'] = 'all'\n",
    "        cleaned_data['dest'] = 'KIS' \n",
    "      \n",
    "\n",
    "    cleaned_data.to_csv('./../../../data/paav_cargo/agg_data/freight_aggregation__' +\n",
    "                            str(crt_year) + '_analysis'+ str(analysis_type) + '_' + regional_flag+ '_' + aircraft_flag +\n",
    "                        '.csv', mode='a', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f535bb-d4e0-4145-9e8b-8eb8fdf7f8f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "years_list = [yr for yr in range (1990,2024)]\n",
    "\n",
    "for analysis_type in range(0,11):\n",
    "    for regional_flag in [ 'alldistance' , 'regional']:\n",
    "        for aircraft_flag in ['jetsandnonjets', 'nonjets','jets']:\n",
    "            for crt_year in years_list:\n",
    "                data_file = './../../../data/paav_cargo/agg_data/freight_aggregation__' + \\\n",
    "                                    str(crt_year) + '_analysis'+ str(analysis_type)+ '_' + regional_flag+ '_' + aircraft_flag +'.csv'\n",
    "                if os.path.exists(data_file): os.remove(data_file), print(\"Deleted file \" +data_file + \".\")\n",
    "                else: print(\"The file \" +data_file + \" does not exist\")\n",
    "\n",
    "                freight_aggregation(crt_year, 'FREIGHT', analysis_type, regional_flag, aircraft_flag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac50a8fb-b13e-430f-8d3a-03d0fbc782b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
